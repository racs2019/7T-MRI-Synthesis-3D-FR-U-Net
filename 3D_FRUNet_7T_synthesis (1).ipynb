{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import io\n",
        "import glob\n",
        "import datetime\n",
        "import zipfile\n",
        "import random\n",
        "import requests\n",
        "import numpy as np\n",
        "import nibabel as nib\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torchio as tio\n",
        "from scipy.ndimage import gaussian_filter\n",
        "from sklearn.model_selection import train_test_split\n",
        "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"
      ],
      "metadata": {
        "id": "0UhR98hKGehv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o2be3x0zD2uu"
      },
      "outputs": [],
      "source": [
        "def load_nifti(file_path):\n",
        "    \"\"\"\n",
        "    Load a NIfTI file and normalize it to [-1,1].\n",
        "    \"\"\"\n",
        "    img = nib.load(file_path)\n",
        "    data = img.get_fdata()\n",
        "    data = (data/4095)\n",
        "    return data.astype(np.float32)\n",
        "\n",
        "def extract_patches_corrected(volume, patch_size=(64, 64, 64), stride=32):\n",
        "    \"\"\"\n",
        "    Extracts 3D patches from the given MRI volume while ensuring correct shape.\n",
        "\n",
        "    Args:\n",
        "        volume (numpy array): Input MRI volume of shape (H, W, D).\n",
        "        patch_size (tuple): Size of the 3D patch (default: 64x64x64).\n",
        "        stride (int): Stride for patch extraction.\n",
        "\n",
        "    Returns:\n",
        "        numpy array: Extracted patches with shape (num_patches, 64, 64, 64, 1).\n",
        "    \"\"\"\n",
        "\n",
        "    # Ensure the input volume shape is (H, W, D) and add channel dimension (C, H, W, D)\n",
        "    volume = np.expand_dims(volume, axis=0)  # (1, H, W, D) for TorchIO\n",
        "\n",
        "    # Convert the NumPy array to a TorchIO ScalarImage\n",
        "    image = tio.ScalarImage(tensor=volume)\n",
        "\n",
        "    # Create a subject containing the image\n",
        "    subject = tio.Subject(mri=image)\n",
        "\n",
        "    # Define the grid sampler for patch extraction\n",
        "    patch_sampler = tio.GridSampler(\n",
        "        subject,\n",
        "        patch_size=patch_size,\n",
        "        patch_overlap=(stride, stride, stride)\n",
        "    )\n",
        "\n",
        "    # Extract patches and convert to NumPy array\n",
        "    patches = np.array([patch['mri'][tio.DATA].numpy() for patch in patch_sampler])\n",
        "\n",
        "    # Remove extra singleton dimensions\n",
        "    #patches = patches.squeeze(axis=(1, -2, -1))  # Remove unnecessary dimensions\n",
        "\n",
        "    # Add the final channel dimension to match TensorFlow expectations\n",
        "    patches = np.expand_dims(patches, axis=-1)\n",
        "\n",
        "    return patches\n",
        "\n",
        "def load_and_extract_patches(synthetic_files, ground_truth_files, patch_size=(64, 64, 64), stride=32):\n",
        "    \"\"\"\n",
        "    Load NIfTI files and extract patches for synthetic and ground truth volumes.\n",
        "\n",
        "    Args:\n",
        "        synthetic_files (list): List of paths to synthetic NIfTI files.\n",
        "        ground_truth_files (list): List of paths to ground truth NIfTI files.\n",
        "        patch_size (tuple): Dimensions of the 3D patch.\n",
        "        stride (int): Step size for sliding window.\n",
        "\n",
        "    Returns:\n",
        "        tuple: Synthetic and ground truth patches as NumPy arrays.\n",
        "    \"\"\"\n",
        "    synthetic_patches = []\n",
        "    ground_truth_patches = []\n",
        "\n",
        "    for synthetic_path, ground_truth_path in zip(synthetic_files, ground_truth_files):\n",
        "        print(f\"Processing: {synthetic_path} and {ground_truth_path}\")\n",
        "\n",
        "        # Load and normalize volumes\n",
        "        synthetic_volume = load_nifti(synthetic_path)\n",
        "        ground_truth_volume = load_nifti(ground_truth_path)\n",
        "\n",
        "        # Extract patches\n",
        "        synthetic_patches.append(extract_patches_corrected(synthetic_volume, patch_size, stride))\n",
        "        ground_truth_patches.append(extract_patches_corrected(ground_truth_volume, patch_size, stride))\n",
        "\n",
        "    # Concatenate patches from all files\n",
        "    synthetic_patches = np.concatenate(synthetic_patches, axis=0)\n",
        "    ground_truth_patches = np.concatenate(ground_truth_patches, axis=0)\n",
        "\n",
        "    return synthetic_patches, ground_truth_patches\n",
        "\n",
        "synthetic_files = [\n",
        "    \"/notebooks/data/ALLT1w/sub-01_ses-1_T1w_defaced_registered.nii.gz\",\n",
        "    \"/notebooks/data/ALLT1w/sub-02_ses-1_T1w_defaced_registered.nii.gz\",\n",
        "    \"/notebooks/data/ALLT1w/sub-03_ses-1_T1w_defaced_registered.nii.gz\",\n",
        "    \"/notebooks/data/ALLT1w/sub-04_ses-1_T1w_defaced_registered.nii.gz\",\n",
        "    \"/notebooks/data/ALLT1w/sub-05_ses-1_T1w_defaced_registered.nii.gz\",\n",
        "    \"/notebooks/data/ALLT1w/sub-06_ses-1_T1w_defaced_registered.nii.gz\",\n",
        "    \"/notebooks/data/ALLT1w/sub-07_ses-1_T1w_defaced_registered.nii.gz\",\n",
        "    \"/notebooks/data/ALLT1w/sub-09_ses-1_T1w_defaced_registered.nii.gz\",\n",
        "    \"/notebooks/data/ALLT1w/sub-10_ses-1_T1w_defaced_registered.nii.gz\"\n",
        "]\n",
        "\n",
        "ground_truth_files = [\n",
        "    \"/notebooks/data/ALLT1w/sub-01_ses-2_T1w_defaced_registered.nii.gz\",\n",
        "    \"/notebooks/data/ALLT1w/sub-02_ses-2_T1w_defaced_registered.nii.gz\",\n",
        "    \"/notebooks/data/ALLT1w/sub-03_ses-2_T1w_defaced_registered.nii.gz\",\n",
        "    \"/notebooks/data/ALLT1w/sub-04_ses-2_T1w_defaced_registered.nii.gz\",\n",
        "    \"/notebooks/data/ALLT1w/sub-05_ses-2_T1w_defaced_registered.nii.gz\",\n",
        "    \"/notebooks/data/ALLT1w/sub-06_ses-2_T1w_defaced_registered.nii.gz\",\n",
        "    \"/notebooks/data/ALLT1w/sub-07_ses-2_T1w_defaced_registered.nii.gz\",\n",
        "    \"/notebooks/data/ALLT1w/sub-09_ses-2_T1w_defaced_registered.nii.gz\",\n",
        "    \"/notebooks/data/ALLT1w/sub-10_ses-2_T1w_defaced_registered.nii.gz\"\n",
        "]\n",
        "\n",
        "# Extract patches\n",
        "patch_size = (64, 64, 64)\n",
        "stride = 32\n",
        "\n",
        "synthetic_patches, ground_truth_patches = load_and_extract_patches(\n",
        "    synthetic_files, ground_truth_files, patch_size, stride\n",
        ")\n",
        "\n",
        "synthetic_patches = np.squeeze(synthetic_patches, axis=1)\n",
        "ground_truth_patches = np.squeeze(ground_truth_patches, axis=1)\n",
        "\n",
        "# Print the shapes of the extracted patches\n",
        "print(\"Synthetic patches shape:\", synthetic_patches.shape)\n",
        "print(\"Ground truth patches shape:\", ground_truth_patches.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize one input and ground truth patch\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(synthetic_patches[1000, :, :, :, 0][20], cmap='gray')\n",
        "plt.title(\"Synthetic Patch (Slice 32)\")\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(ground_truth_patches[1000, :, :, :, 0][20], cmap='gray')\n",
        "plt.title(\"Ground Truth Patch (Slice 32)\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GQC9KQsCEK9p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def residual_block(x, filters):\n",
        "    \"\"\" Residual Block to enhance fine details in feature maps. \"\"\"\n",
        "    res = layers.Conv3D(filters, (3, 3, 3), padding='same')(x)\n",
        "    res = layers.PReLU()(res)\n",
        "    res = layers.Conv3D(filters, (3, 3, 3), padding='same')(res)\n",
        "\n",
        "    # Ensure `x` has the same number of channels as `res`\n",
        "    if x.shape[-1] != filters:\n",
        "        x = layers.Conv3D(filters, (1, 1, 1), padding='same', activation='linear')(x)\n",
        "\n",
        "    return layers.Add()([x, res])  # Residual connection to refine features\n",
        "\n",
        "def multi_scale_fusion(x, filters):\n",
        "    \"\"\" Multi-scale feature extraction to retain details at different receptive fields. \"\"\"\n",
        "    s1 = layers.Conv3D(filters, (1, 1, 1), padding='same')(x)\n",
        "    s3 = layers.Conv3D(filters, (3, 3, 3), padding='same')(x)\n",
        "    s5 = layers.Conv3D(filters, (5, 5, 5), padding='same')(x)\n",
        "    return layers.concatenate([s1, s3, s5], axis=-1)\n",
        "\n",
        "def build_optimized_unet_autoencoder(input_shape=(64, 64, 64, 1)):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "    # Encoder\n",
        "    c1 = layers.Conv3D(32, (5, 5, 5), padding='same')(inputs)\n",
        "    c1 = layers.PReLU()(c1)\n",
        "    c1 = layers.Conv3D(32, (3, 3, 3), padding='same')(c1)\n",
        "    c1 = layers.PReLU()(c1)\n",
        "    c1 = layers.LayerNormalization()(c1)\n",
        "    p1 = layers.MaxPooling3D((2, 2, 2))(c1)  # 32x32x32\n",
        "\n",
        "    c2 = layers.Conv3D(64, (3, 3, 3), padding='same')(p1)\n",
        "    c2 = layers.PReLU()(c2)\n",
        "    c2 = layers.Conv3D(64, (3, 3, 3), padding='same')(c2)\n",
        "    c2 = layers.PReLU()(c2)\n",
        "    c2 = layers.LayerNormalization()(c2)\n",
        "    p2 = layers.MaxPooling3D((2, 2, 2))(c2)  # 16x16x16\n",
        "\n",
        "    c3 = layers.Conv3D(128, (3, 3, 3), padding='same')(p2)\n",
        "    c3 = layers.PReLU()(c3)\n",
        "    c3 = layers.Conv3D(128, (3, 3, 3), padding='same')(c3)\n",
        "    c3 = layers.PReLU()(c3)\n",
        "    c3 = layers.LayerNormalization()(c3)\n",
        "    p3 = layers.MaxPooling3D((2, 2, 2))(c3)  # 8x8x8\n",
        "\n",
        "    c4 = layers.Conv3D(256, (3, 3, 3), padding='same')(p3)\n",
        "    c4 = layers.PReLU()(c4)\n",
        "    c4 = layers.Conv3D(256, (3, 3, 3), padding='same')(c4)\n",
        "    c4 = layers.PReLU()(c4)\n",
        "    c4 = layers.LayerNormalization()(c4)\n",
        "\n",
        "    # Decoder with Residual Blocks and Multi-Scale Fusion\n",
        "    u3 = layers.Conv3DTranspose(128, (3, 3, 3), strides=(2, 2, 2), padding='same')(c4)  # 16x16x16\n",
        "    u3 = layers.concatenate([u3, c3])  # Now both are (16,16,16,128)\n",
        "    u3 = residual_block(u3, 128)\n",
        "    u3 = multi_scale_fusion(u3, 128)\n",
        "    u3 = layers.LayerNormalization()(u3)\n",
        "\n",
        "    u2 = layers.Conv3DTranspose(64, (3, 3, 3), strides=(2, 2, 2), padding='same')(u3)  # 32x32x32\n",
        "    u2 = layers.concatenate([u2, c2])  # Now both are (32,32,32,64)\n",
        "    u2 = residual_block(u2, 64)\n",
        "    u2 = multi_scale_fusion(u2, 64)\n",
        "    u2 = layers.LayerNormalization()(u2)\n",
        "\n",
        "    u1 = layers.Conv3DTranspose(32, (3, 3, 3), strides=(2, 2, 2), padding='same')(u2)  # 64x64x64\n",
        "    u1 = layers.concatenate([u1, c1])  # Now both are (64,64,64,32)\n",
        "    u1 = residual_block(u1, 32)\n",
        "    u1 = multi_scale_fusion(u1, 32)\n",
        "    u1 = layers.LayerNormalization()(u1)\n",
        "\n",
        "    outputs = layers.Conv3D(1, (1, 1, 1), activation='sigmoid', padding='same')(u1)  # Sigmoid for better contrast\n",
        "\n",
        "    model = Model(inputs, outputs)\n",
        "    return model\n",
        "\n",
        "# Hybrid Loss Function with Higher SSIM Weight\n",
        "def hybrid_loss(y_true, y_pred):\n",
        "    mse_loss = tf.keras.losses.MeanSquaredError()(y_true, y_pred)\n",
        "    ssim_component = 1 - tf.reduce_mean(tf.image.ssim(y_true, y_pred, max_val=1.0))\n",
        "    return mse_loss + 0.7 * ssim_component  # Increased SSIM weight for better structure preservation\n",
        "\n",
        "\n",
        "# Build Model\n",
        "autoencoder = build_optimized_unet_autoencoder()\n",
        "autoencoder.compile(optimizer=Adam(learning_rate=2e-5), loss=hybrid_loss, metrics=['mse'])\n",
        "\n",
        "# Summary\n",
        "autoencoder.summary()"
      ],
      "metadata": {
        "id": "CiNW5T3BELnr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define callbacks\n",
        "checkpoint = ModelCheckpoint(\"best_7T.keras\", save_best_only=True, monitor=\"val_loss\", verbose=1)\n",
        "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True)\n",
        "\n",
        "autoencoder.compile(optimizer=Adam(learning_rate=2e-5), loss=hybrid_loss, metrics=['mse'])\n",
        "\n",
        "# Train the model with fine-tuning\n",
        "autoencoder.fit(\n",
        "    synthetic_patches,  # 3T MRI patches\n",
        "    ground_truth_patches,  # 7T MRI patches\n",
        "    epochs=40,\n",
        "    batch_size=8,\n",
        "    validation_split=0.1,\n",
        "    callbacks=[checkpoint, early_stopping]\n",
        ")"
      ],
      "metadata": {
        "id": "QoZ2bnFbEOth"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict and visualize one patch\n",
        "testt = tf.expand_dims(synthetic_patches, axis=-1)\n",
        "predicted_patches = autoencoder.predict(testt[:150])\n",
        "\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.imshow(synthetic_patches[100, :, :, :, 0][32], cmap='gray')\n",
        "plt.title(\"Synthetic Patch (Slice 32)\")\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.imshow(ground_truth_patches[100, :, :, :, 0][32], cmap='gray')\n",
        "plt.title(\"Ground Truth Patch (Slice 32)\")\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.imshow(predicted_patches[100, :, :, :, 0][32], cmap='gray')\n",
        "plt.title(\"Predicted Patch (Slice 32)\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MmLx9gNWFqag"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_psnr_ssim_nmse(ground_truth_volume, refined_volume):\n",
        "    \"\"\"\n",
        "    Computes PSNR, SSIM, and NMSE for 3D MRI volumes slice-by-slice and returns their mean.\n",
        "    \"\"\"\n",
        "    # Ensure both volumes have the same shape\n",
        "    assert ground_truth_volume.shape == refined_volume.shape, \"Volume shapes do not match!\"\n",
        "\n",
        "    for j in range(3):\n",
        "\n",
        "      psnr_values = []\n",
        "      ssim_values = []\n",
        "      nmse_values = []\n",
        "\n",
        "      num_slices = ground_truth_volume.shape[j]  # Assuming slices along the Z-axis\n",
        "\n",
        "      for i in range(num_slices):\n",
        "\n",
        "          if j == 0:\n",
        "            gt_slice = ground_truth_volume[i, :, :]\n",
        "            pred_slice = refined_volume[i, :, :]\n",
        "\n",
        "          if j == 1:\n",
        "            gt_slice = ground_truth_volume[:, i, :]\n",
        "            pred_slice = refined_volume[:, i, :]\n",
        "\n",
        "          if j == 2:\n",
        "            gt_slice = ground_truth_volume[:, :, i]\n",
        "            pred_slice = refined_volume[:, :, i]\n",
        "\n",
        "          # Compute MSE\n",
        "          mse = np.mean((gt_slice - pred_slice) ** 2)\n",
        "\n",
        "          # Compute PSNR (handle zero-MSE case)\n",
        "          psnr_value = psnr(gt_slice, pred_slice, data_range=4095)\n",
        "\n",
        "          # Compute SSIM\n",
        "          ssim_value = ssim(gt_slice, pred_slice, data_range=4095, gaussian_weights=True)\n",
        "\n",
        "          # Compute NMSE (Normalized Mean Squared Error)\n",
        "          norm_factor = np.mean(gt_slice ** 2)  # Normalize by the mean squared value of the ground truth\n",
        "          nmse_value = mse / norm_factor if norm_factor > 0 else 0  # Avoid division by zero\n",
        "\n",
        "          psnr_values.append(psnr_value)\n",
        "          ssim_values.append(ssim_value)\n",
        "          nmse_values.append(nmse_value)\n",
        "\n",
        "      # Compute mean values across all slices, ignoring infinite PSNR values\n",
        "      mean_psnr = np.mean([p for p in psnr_values if np.isfinite(p)]) if psnr_values else 0\n",
        "      mean_ssim = np.mean(ssim_values) if ssim_values else 0\n",
        "      mean_nmse = np.mean(nmse_values) if nmse_values else 0\n",
        "\n",
        "      print(f'Axis {j}: Mean PSNR: {mean_psnr:.2f} dB, Mean SSIM: {mean_ssim:.4f}, Mean NMSE: {mean_nmse:.6f}')\n",
        "\n",
        "    return mean_psnr, mean_ssim, mean_nmse"
      ],
      "metadata": {
        "id": "xgoIhxZ4Fzm6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_patches(volume, patch_size, stride):\n",
        "    \"\"\"\n",
        "    Extract 3D patches from a volume, ensuring full coverage with padding at edges.\n",
        "    \"\"\"\n",
        "    h, w, d = volume.shape\n",
        "    ps_h, ps_w, ps_d = patch_size\n",
        "\n",
        "    patches = []\n",
        "    positions = []\n",
        "\n",
        "    for i in range(0, h, stride):\n",
        "        for j in range(0, w, stride):\n",
        "            for k in range(0, d, stride):\n",
        "                # Ensure patches at edges do not exceed image size\n",
        "                i_end = min(i + ps_h, h)\n",
        "                j_end = min(j + ps_w, w)\n",
        "                k_end = min(k + ps_d, d)\n",
        "\n",
        "                # Extract patch\n",
        "                patch = volume[i:i_end, j:j_end, k:k_end]\n",
        "\n",
        "                # If patch is smaller due to edge effects, pad it\n",
        "                pad_h = ps_h - (i_end - i)\n",
        "                pad_w = ps_w - (j_end - j)\n",
        "                pad_d = ps_d - (k_end - k)\n",
        "\n",
        "                patch = np.pad(patch, ((0, pad_h), (0, pad_w), (0, pad_d)), mode='reflect')\n",
        "\n",
        "                patches.append(patch)\n",
        "                positions.append((i, j, k))\n",
        "\n",
        "    patches = np.array(patches)\n",
        "    patches = np.expand_dims(patches, axis=-1)  # Add channel dimension\n",
        "    return patches, positions\n",
        "\n",
        "def gaussian_weight_map(shape, sigma=0.5):\n",
        "    \"\"\"Generate a Gaussian weighting map for smooth patch blending.\"\"\"\n",
        "    mask = np.ones(shape, dtype=np.float32)\n",
        "    weights = gaussian_filter(mask, sigma=sigma)\n",
        "    return weights / np.max(weights)  # Normalize\n",
        "\n",
        "def reconstruct_volume(patches, positions, original_shape, patch_size):\n",
        "    \"\"\"\n",
        "    Reconstruct a 3D volume from overlapping patches using Gaussian blending.\n",
        "    \"\"\"\n",
        "    h, w, d = original_shape\n",
        "    ps_h, ps_w, ps_d = patch_size\n",
        "\n",
        "    reconstructed = np.zeros(original_shape, dtype=np.float32)\n",
        "    counts = np.zeros(original_shape, dtype=np.float32)\n",
        "\n",
        "    weight_map = gaussian_weight_map((ps_h, ps_w, ps_d))  # Generate smooth weight map\n",
        "\n",
        "    for idx, (i, j, k) in enumerate(positions):\n",
        "        i_end = min(i + ps_h, h)\n",
        "        j_end = min(j + ps_w, w)\n",
        "        k_end = min(k + ps_d, d)\n",
        "\n",
        "        patch = patches[idx, ..., 0]  # Extract patch\n",
        "        patch = patch[:i_end-i, :j_end-j, :k_end-k]  # Crop to match original size if needed\n",
        "        weight = weight_map[:i_end-i, :j_end-j, :k_end-k]  # Crop weight map similarly\n",
        "\n",
        "        reconstructed[i:i_end, j:j_end, k:k_end] += patch * weight\n",
        "        counts[i:i_end, j:j_end, k:k_end] += weight\n",
        "\n",
        "    counts[counts == 0] = 1  # Avoid division by zero\n",
        "    return reconstructed / counts  # Normalize final volume\n",
        "\n",
        "def process_nifti_with_autoencoder(input_nifti_path, ground_truth_nifti_path, output_nifti_path, autoencoder, patch_size=(64,64,64), stride=32):\n",
        "    \"\"\"\n",
        "    Processes a single NIfTI file through the autoencoder and saves the reconstructed volume.\n",
        "    \"\"\"\n",
        "    # Load NIfTI file\n",
        "    nifti_img = nib.load(input_nifti_path)\n",
        "    volume = nifti_img.get_fdata()\n",
        "\n",
        "        # Load NIfTI file\n",
        "    nifti_gt = nib.load(ground_truth_nifti_path)\n",
        "    volume_gt = nifti_gt.get_fdata()\n",
        "\n",
        "\n",
        "    # Normalize input to [-1,1]\n",
        "    volume = (volume/4095)\n",
        "\n",
        "    # Extract patches\n",
        "    synthetic_patches, positions = extract_patches(volume, patch_size, stride)\n",
        "\n",
        "    # Predict refined patches\n",
        "    refined_patches = autoencoder.predict(synthetic_patches)\n",
        "\n",
        "    # Reconstruct volume\n",
        "    refined_volume = reconstruct_volume(refined_patches, positions, volume.shape, patch_size)\n",
        "\n",
        "    # Denormalize input\n",
        "    refined_volume = (refined_volume) * 4095\n",
        "\n",
        "    # Example Usage:\n",
        "    mean_psnr, mean_ssim, mean_nmse = compute_psnr_ssim_nmse(volume_gt, refined_volume)\n",
        "\n",
        "    # Save as NIfTI\n",
        "    refined_nifti = nib.Nifti1Image(refined_volume, nifti_img.affine)\n",
        "    nib.save(refined_nifti, output_nifti_path)\n",
        "    print(f\"Saved refined MRI: {output_nifti_path}\")\n",
        "\n",
        "# Example Usage\n",
        "input_nifti_path = \"/notebooks/data/ALLT1w/sub-08_ses-1_T1w_defaced_registered.nii.gz\"\n",
        "ground_truth_nifti_path = \"/notebooks/data/ALLT1w/sub-08_ses-2_T1w_defaced_registered.nii.gz\"\n",
        "output_nifti_path = \"Test_sub08_SAE.nii.gz\"\n",
        "\n",
        "process_nifti_with_autoencoder(input_nifti_path, ground_truth_nifti_path, output_nifti_path, autoencoder, patch_size=(64,64,64), stride=32)"
      ],
      "metadata": {
        "id": "coc--bGuF14V"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}